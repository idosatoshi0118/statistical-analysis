---
title: "STAT 526 HW 1"
author: "Satoshi Ido (ID: 34788706)"
date: 23 January 2023
output: pdf_document
---
```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE)
```

Library import
```{r}
library("tidyverse")
library("dplyr")
library("car")
library("ggplot2")
library("reshape2")
library("caTools")
library("Rcmdr")
library("MASS")
```

data import
```{r message = FALSE}
data(Cars93, package = "MASS")
Cars93
```

data display
```{r message = FALSE}
View(Cars93)
# number of rows
nrow(Cars93)
# data type of each column
str(Cars93)
# if there is null values in the dataset
# is.na(Cars93)
# name of the columns in the dataset
names(Cars93)

```

create the response variable "MPG.avg" by averaging "MPG.city" and "MPG.highway"
```{r message = FALSE}
df <- Cars93 %>%
        mutate(MPG.avg = (Cars93$MPG.highway + Cars93$MPG.city) / 2)
```

check the distribution of response (histogram, qq-plot) â†’ box-cox
```{r meesage = FALSE, out.width = "50%"}
plot(density(df$MPG.avg))
qqnorm(df$MPG.avg, pch = 1, frame = FALSE)
qqline(df$MPG.avg, col = "steelblue", lwd = 2)
```


box-cox
```{r message = FALSE, out.width = "50%"}
## there is no 0 in MPG.avg
min(df$MPG.avg); max(df$MPG.avg)

df2 <- df %>%
        na.omit() %>%
        mutate(Cylinders = as.numeric(.$Cylinders)) %>%
        subset(select = -c(MPG.city, MPG.highway, Min.Price, Max.Price, Manufacturer, Model, Make))

# boxcox
p1 <- powerTransform(df2$MPG.avg)
df2$MPG.avg <- bcPower(df2$MPG.avg, p1$lambda)

# ggplot(data = df2, aes(x = (MPG.avg^lambda -1)/lambda)) + geom_histogram(fill = "blue", bins = 15)

# plot again
plot(density(df2$MPG.avg))
qqnorm(df2$MPG.avg, pch = 1, frame = FALSE)
qqline(df2$MPG.avg, col = "steelblue", lwd = 2)
```



check the Pairwise Pearson Correlations
From the Person Correlation matrix, there appears to be a significant amount of correlated relations between the predictor variables. It will thus be necessary to ensure that multicollinearity can be
a concern later in my model.
```{r message = FALSE, out.width = "40%"}
df %>%
    na.omit() %>%
    mutate(Cylinders = as.numeric(.$Cylinders)) %>%
    subset(select = -c(MPG.city, MPG.highway, Min.Price, Max.Price, Manufacturer, Model, Make)) %>%
    # remove the non-numerical variables
    # https://bit.ly/3ZXRAMH
    .[, colnames(.)[!grepl("factor|logical|character", sapply(., class))]] %>%
    cor(., ) %>%
    round(., 2) %>%
    melt() %>%
    ggplot(., aes(x = Var1, y = Var2, fill = value)) +
        geom_tile() +
        scale_fill_distiller(direction = +1) +
        geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
        theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Linear Models to grasp the trend
```{r message = FALSE, out.width = "50%"}
# simple linear model
# I use my intuition for now. Simply, I suppose the size of a car and engine and fuel tank are correlated with the car efficiency
simple <- lm(MPG.avg ~ Weight + Width + Length +
                    Fuel.tank.capacity + Horsepower,
                    data = df2
                    )
# Only weight is significant
summary(simple)
# Regression Diagnostics
simple.infl <- influence.measures(simple)
# print(simple.infl)

# check the vif. In fact, Weight has the highest vif (16.69)
vif(simple)

# get rid of the weight parameter
simple_v2 <- lm(MPG.avg ~ Width + Length +
                    Fuel.tank.capacity + Horsepower,
                    data = df2
                    )
# Indeed, Fuel.tank.capacity and Horsepower became significant. Yet, this model is not preferrable in terms of Interpretability.
summary(simple_v2)

# check the vif. There are none high vif variables
vif(simple_v2)
```

stepwise with AIC and BIC
```{r message = FALSE}
# use stepwise methods based on AIC and BIC
m1 <- lm(data = df2, MPG.avg ~ .)
M1_BIC <- stepwise(m1, direction = "forward/backward", criterion = "BIC")
M1_AIC <- stepwise(m1, direction = "forward/backward", criterion = "AIC")

# check the summary. M1_AIC has insignificant variable; hence, do not use M1_AIC this time. Interpret M1_BIC only
summary(M1_BIC)
summary(M1_AIC)

# vif
vif(M1_BIC)

# since Weight's vif is higher than 10 so I will try to remove some of variables while maintaing R-squared score, and Fuel.tank.capacity is found that getting rid of Fuel.tank.capacity
m2 <- lm(data = df2, MPG.avg ~ Price + Cylinders + Wheelbase + Weight)
M2_BIC <- stepwise(m2, direction = "forward/backward", criterion = "BIC")
# vif of Weight become under 10.
vif(M2_BIC)

# check the summary
summary(M2_BIC)

# check the normality by residual plot
plot(df2$Weight, resid(M2_BIC), ylab = "Residuals", xlab = "Weight", main = "Car Efficiency")
abline(0, 0)
```

