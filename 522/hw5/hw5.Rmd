---
title: "HW5"
author: "Satoshi Ido"
date: 26 February 2024
output: pdf_document
header-includes:
  - "\\usepackage{listings}"
  - "\\lstset{breaklines=true,breakatwhitespace=true}"
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  tidy = TRUE
)
```

```{r}
library("tidyverse")
library("survey")
library("sampling")
library("foreign")
library("haven")
```

```{r warning=FALSE, message=FALSE, include=FALSE}
# Create the input_dir (input directory)
INPUT_DIR <- "/Users/satoshiido/Documents/programming/statistical-analysis/522/hw5/data"

# If INPUT_DIR has not been created yet, create it
if (!dir.exists(INPUT_DIR)) {
  dir.create(INPUT_DIR)
}

# Create the output_dir (output directory)
OUTPUT_DIR <- "/Users/satoshiido/Documents/programming/statistical-analysis/522/hw5/output"

# If OUTPUT_DIR has not been created yet, create it
if (!dir.exists(OUTPUT_DIR)) {
  dir.create(OUTPUT_DIR)
}

# Read CSV files using a function to specify the directory automatically
read_csv <- function(name, ...) {
  path <- file.path(INPUT_DIR, paste0(name, ".csv"))
  print(paste("Load:", path))
  return(read.csv(path, ...))
}
```

```{r}
# # Define the source directory and destination directory
# current_note_path <- getwd()
# source_dir <- file.path(current_note_path, "522/hw5/")
# destination_dir <- INPUT_DIR

# # Get a list of CSV files in the source directory
# csv_files <- fs::dir_ls(source_dir, regexp = "\\.csv$", recurse = TRUE)
# sas_files <- fs::dir_ls(source_dir, regexp = "\\.sas7bdat$", recurse = TRUE)

# # Move each CSV file to the destination directory
# for (file in csv_files) {
#   fs::file_move(file, destination_dir)
#   cat("Moved csv file:", file, "\n")
# }
```

# Question 1
data import
```{r warning=FALSE, message=FALSE}
# You can read SAS file directly using the haven package.
shapedata <- read_csv("shapespop")
```

## SRS
```{r warning=FALSE, message=FALSE, include=TRUE}
# SRS (the same as the one used in Homework 3)
# Set seed
set.seed(49)

# Computing the sampling weights
N <- nrow(shapedata)
index_SRS <- sample(1:N, 200, replace = FALSE)

SRS <- shapedata[index_SRS, ]

n <- nrow(SRS)
SRS$probability <- rep(n / 20000, n)
SRS$sampwt <- rep(20000 / n, n)

# Creating a SRS sample
SRS_sample <- svydesign(ids = ~1,
                        weights = ~SRS$sampwt,
                        fpc = rep(20000, 200),
                        data = SRS)

# Calculate mean with confidence intervals for area
SRS_area_mean <- svymean(~area, design = SRS_sample)
print(SRS_area_mean)
# Confidence Intervals for Model Parameters
confint(SRS_area_mean, df = 199)

# Calculate total with confidence intervals for gray objects
SRS_gray_total <- svytotal(~color, design = SRS_sample)
print(SRS_gray_total)
confint(SRS_gray_total, df = 199)
```

## Stratified Sampling
```{r warning=FALSE, message=FALSE, include=TRUE}
#Computing Proportional Allocation that will be used later
popsize <- table(shapedata$shape)
propalloc <- 200 * popsize / sum(popsize)
propalloc #sample size for circle is 50 and 150 for square

# Sort the population by stratum
shapedata_sorted <- shapedata[order(shapedata$shape), ]

# Use the strata function to select the units for the sample
index_STR <- strata(shapedata_sorted,
              stratanames = c("shape"),
              size = c(50, 150),
              method = "srswor")
# Check if we randomly selected 50 circles and 150 squares
table(index_STR$shape)

# extract data for the stratified sample we got
STR <- getdata(shapedata_sorted, index_STR)
head(STR)

# Calculate sampling weights
STR$sampwt <- 1/STR$Prob
# Check that the sampling weights sum to the population sizes for each stratum
tapply(STR$sampwt, STR$shape, sum)

# From the previous step, we know that the population size is 5000 for circle and 15000 for square
# Now, we can add this information to the sample we drew for later use (i.e.,fpc)
STR$popsize[STR$shape == "circle"] <- 5000
STR$popsize[STR$shape == "square"] <- 15000
STR$popsize <- as.numeric(STR$popsize)

# Create sample design
STR_sample <- svydesign(id = ~1, strata = ~STR$shape,
                        weights = ~STR$sampwt,
                        fpc = ~STR$popsize,
                        data = STR)

# Calculate mean and CI for area
STR_area_mean <- svymean(~area, design = STR_sample)
print(STR_area_mean)
confint(STR_area_mean,  df = 198)

# Calculate total and CI for gray objects
STR_gray_total <- svytotal(~color, design = STR_sample)
print(STR_gray_total)
confint(STR_gray_total, df = 198)
```

# Question 2

## SRS
```{r warning=FALSE, message=FALSE, include=TRUE}
#You can read SAS file directly using the haven package.
baseballdata <- as.data.frame(read_csv('baseball'))
names(baseballdata)

# We can compute population size for each stratum now. This will save our later.
baseballdata <- baseballdata %>%
  group_by(baseballdata$team) %>%
  mutate(popsize = n()) %>%
  mutate(logsal = ifelse(salary > 0, log(salary), NA))

# SRS
# Set seed
set.seed(49)

# Computing the sampling weights
N <- nrow(baseballdata)
index2_SRS <- sample(1:N, 150, replace = FALSE)

SRS2 <- baseballdata[index2_SRS, ]

n <- nrow(SRS2)
SRS2$probability <- rep(n / 797, n)
SRS2$sampwt <- rep(797 / n, n)

# Creating a SRS sample
SRS2_sample <- svydesign(ids = ~1,
                        weights = ~SRS2$sampwt,
                        fpc = rep(797, 150),
                        data = SRS2)

# Calculate mean with confidence intervals for pitchers
SRS2_pitchers_mean <- svymean(~pos, design = SRS2_sample)
print(SRS2_pitchers_mean)
confint(SRS2_pitchers_mean, df = 149)


# Calculate mean with confidence intervals for logsal
SRS2_logsal_mean <- svymean(~logsal, design = SRS2_sample)
print(SRS2_logsal_mean)
confint(SRS2_logsal_mean, df = 149)
```


## Stratified Sampling
```{r warning=FALSE, message=FALSE, include=TRUE}
set.seed(49)

# Compute Proportional Allocation that will be used later
popsize2 <- table(baseballdata$team)
propalloc2 <- 150 * popsize2 / sum(popsize2)
propalloc2

# Round all proportions to nearest integers
propalloc2_int <- round(propalloc2)
propalloc2_int
sum(propalloc2_int) #From this, we know from each stratum we need to draw 5 persons

# Sort the population by stratum
baseballdata_sorted <- baseballdata[order(baseballdata$team), ]

# Use the strata function to select the units for the sample
index2_STR <- strata(baseballdata_sorted,
              stratanames = c("team"),
              size=c(5,5,5,5,5,5,5,5,5,5,
                     5,5,5,5,5,5,5,5,5,5,
                     5,5,5,5,5,5,5,5,5,5),
              method="srswor")
# Check if we randomly selected 5 persons for each stratum
table(index2_STR$team)

# extract data for the stratified sample we got
# Before this, we calculate the size of each team 
baseballdata_sorted %>% add_count(team, sort = T, name = "popsize")

STR2 <- getdata(baseballdata_sorted,index2_STR)

# Calculate sampling weights
STR2$sampwt <- 1/STR2$Prob


# Check that the sampling weights sum to the population sizes for each stratum
tapply(STR2$sampwt, STR2$team, sum)
table(baseballdata_sorted$team)


# Create sample design
STR2_sample <- svydesign(id = ~1, strata = ~STR2$team,
                        weights = ~STR2$sampwt,
                        fpc=~STR2$popsize,
                        data = STR2) 

# Calculate the mean/proportion and CI for pitchers
STR2_pichers_mean <- svymean(~pos, design = STR2_sample)
print(STR2_pichers_mean)
confint(STR2_pichers_mean, df = 120) # df = 150(sample size) - 30(number of strata)

# Calculate mean and CI for logsal
STR2_logsal_mean <- svymean(~logsal, design = STR2_sample)
print(STR2_logsal_mean)
confint(STR2_logsal_mean, df = 120)

# To answer the last question about optimal allocation, we need to look at the variance of each stratum
grp <- group_by(baseballdata, team)
var_team <- summarise(grp, mean = mean(logsal), var = var(logsal), sd = sd(logsal))
print(var_team, n = 30)

# This will generate the boxplot like SAS does
install.packages("ggplot2")
library(ggplot2)
ggplot(baseballdata, aes(x = team, y = logsal, fill=team))+
  stat_boxplot(geom = "errorbar", width = 0.25) + 
  geom_boxplot(alpha = 0.8,          
               fill="#90A4AE", colour="black") +
  stat_summary(fun.y="mean",color="black", shape=5)
```
