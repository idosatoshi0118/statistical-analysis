---
title: "Propensity Score Matching and Analysis"
author: "Satoshi Ido"
output: pdf_document
pandoc_args: ["--lua-filter=color-text.lua"]
header-includes:
  - "\\usepackage{listings}"
  - "\\lstset{breaklines=true,breakatwhitespace=true}"
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  tidy = TRUE
)
```
```{r}
library("ggplot2")
library("tidyverse")
library("MASS")
library("broom")
library("knitr")
```

```{r warning=FALSE, message=FALSE, include=FALSE}

# Create the input_dir (input directory)
INPUT_DIR <- "/Users/satoshiido/Documents/programming/statistical-analysis/causal_inference/data"

# If INPUT_DIR has not been created yet, create it
if (!dir.exists(INPUT_DIR)) {
  dir.create(INPUT_DIR)
}

# Create the output_dir (output directory)
OUTPUT_DIR <- "/Users/satoshiido/Documents/programming/statistical-analysis/causal_inference/output"

# If OUTPUT_DIR has not been created yet, create it
if (!dir.exists(OUTPUT_DIR)) {
  dir.create(OUTPUT_DIR)
}

# Read CSV files using a function to specify the directory automatically
read_csv <- function(name, ...) {
  path <- file.path(INPUT_DIR, paste0(name, ".csv"))
  print(paste("Load:", path))
  return(read.csv(path, ...))
}
```

```{r warning=FALSE, message=FALSE, echo=FALSE}
email_data <- read_csv("Kevin_Hillstrom_MineThatData_E-MailAnalytics")
```

```{r warning=FALSE, message=FALSE}
# create the data w/o the womens E-Mail campaign
male_df <- email_data %>% 
  filter(segment != "Womens E-Mail") %>%
  mutate(treatment = if_else(segment == "Mens E-Mail", 1, 0))

# create the selection biased data
## set the seed
set.seed(1)

## make half depending on the condition
obs_rate_c <- 0.5
obs_rate_t <- 0.5

## create the biased data
biased_data <- male_df %>%
  mutate(
    obs_rate_c = if_else(
      (history > 300) | (recency < 6) | (channel == "Multichannel"), obs_rate_c, 1),
    obs_rate_t = if_else(
      (history > 300) | (recency < 6) | (channel == "Multichannel"), 1, obs_rate_t),
    random_number = runif(n = NROW(male_df))) %>%
    filter((treatment == 0 & random_number < obs_rate_c) | (treatment == 1 & random_number < obs_rate_t))

head(biased_data)
```

# Propensity Score Estimation
```{r warning=FALSE, message=FALSE}
# create the propensity score model using logistic regression, which returns the probability of Y = 1
ps_model <- glm(data = biased_data, formula = treatment ~ recency + history + channel, family = binomial)
```

# Propensity Score Matching
The idea is very simple. A sample is taken from the intervention group and matched with a sample from the non-intervention group that has a propensity score close to that of the sample to form a pair. The difference in the objective variable among the pairs is then calculated and averaged to obtain an estimate of the effect.
Average Treatment effect on Treated (ATT) is defined as follows:
$$
ATT = E[Y(1) - Y(0)] = E[Y|T=1] - E[Y|T=0]
$$

```{r warning=FALSE, message=FALSE}
library("MatchIt")

# perform propensity score matching (matchit -> ATT)
m_near <- matchit(formula = treatment ~ recency + history + channel,
  data = biased_data,
  method = "nearest",
  replace = TRUE)

# get the matched data (The resulting data frame will include all of the original data, along with additional columns for the weights and indices of the matched observations.)
matched_data <- match.data(m_near)

# estimate the effect based on the matched data
PSM_result <- matched_data %>% 
  lm(spend ~ treatment, data = .) %>%
  tidy()
```

# Inverse Probability Weighting; IPW
Using the propensity scores as sample weights, we estimate the expected value of the outcome with intervention (E[Y(1)]) and the expected value of the outcome without intervention (E[Y(0)]) for the given data as a whole. The effect is then estimated by subtracting these expected values
PW uses the value of the propensity score to strech the observed sample size. This increases the number of samples with small Y(1) values, which are relatively difficult to observe due to Z = 0, thus bringing the calculated average closer to the original expected value.

```{r warning=FALSE, message=FALSE}
library("WeightIt")

# perform inverse probability weighting (weightit -> ATE)
weighting <- weightit(formula = treatment ~ recency + history + channel,
  data = biased_data,
  method = "ps",
  estimand = "ATE")

# estimate the effect based on the weighted data
IPW_result <- biased_data %>%
  lm(formula = spend ~ treatment, weights = weighting$weights) %>%
  tidy()

IPW_result
```

Propensity scores were interpreted as being important if their explanatory power for the data exceeded a certain value, and it was desirable for indicators such as the c statistic to exceed a certain value.
In recent years, however, there is a general view that it is important to have a good balance of covariates in the data after weighting or matching using propensity scores (Stuart, 2010).

# Balance Check
```{r warning=FALSE, message=FALSE}
library("cobalt")

# covariates balacne check with matched data
love.plot(m_near, threshold = 0.1)

# covariates balance check with weighted data
love.plot(weighting, threshold = 0.1)
```

Analysis using propensity scores has the practical advantage of eliminating the need for modeling for "Y" and only requiring surveys or interviews regarding how "Z" is determined, which is easier to obtain information on.
Therefore, if you have a wealth of information on how the value of "Y" is determined, there are significant advantages to using regression analysis.

# estimate of the ML based mail-marketing effect

create the data
```{r warning=FALSE, message=FALSE}
# set the seed
set.seed(1)

# generates a random number to include in the training data
train_flag <- sample(NROW(male_df), NROW(male_df)/2, replace = FALSE)

# create the past data (train data) from the non-treatment group
male_df_train <- male_df[train_flag, ] %>% filter(treatment == 0)

# create the future data (test data)
male_df_test <- male_df[-train_flag, ]

# builid the model to predict the probability of the sales among the non-treatment group
predict_model <- glm(
  data = male_df_train,
  formula = conversion ~ recency + history_segment + channel + zip_code,
  family = binomial
)
```

In the future data, only the samples from which interventions actually took place that were eligible for treatment in the process described above are retained, and the rest are deleted.
Similarly, from the non-intervention data, only the samples that were not eligible for delivery in the same process are retained, and the rest are deleted. These operations are performed using `filter()`.
```{r warning=FALSE, message=FALSE}
## obtain the probability of the marketing based on the probability of the sales occurring
pred_cv <- predict(predict_model, newdata = male_df_test, type = "response")
pred_cv_rank <- percent_rank(pred_cv)

## determine email marketing probability based on probability of sales occurring (randomly somewhat)
mail_assign <- sapply(pred_cv_rank, rbinom, n = 1, size = 1)

## create a mail marketing log
ml_male_df <- male_df_test %>%
  mutate(mail_assign = mail_assign, ps = pred_cv_rank) %>%
  filter((treatment == 1 & mail_assign == 1) | (treatment == 0 & mail_assign == 0))
head(ml_male_df)
```

As we know the idea of selection bias, this approach creates the selection bias in the evaluation of the effect of the mail marketing.

```{r warning=FALSE, message=FALSE, echo=FALSE} 
knitr::include_graphics("/Users/satoshiido/Documents/programming/statistical-analysis/causal_inference/pic/ml_marketing_image.png")
```

# RCT and comparison in mean treatment effects
mean difference in the effect of the RCT
```{r warning=FALSE, message=FALSE}
# check the mean difference 
rct_male_lm <- lm(data = male_df_test, formula = spend ~ treatment) %>% tidy()
rct_male_lm
```

mean difference in the effect with selection bias
Since the model based marketing decision biased the distribution of the emails to users who are more likely to generate sales, the estimated values are considered to be affected by the selection bias.
```{r warning=FALSE, message=FALSE}
ml_male_lm <- lm(data = ml_male_df, formula = spend ~ treatment) %>% tidy()
ml_male_lm
```

# Propensity Score Matching and Analysis
Propsensity Score Matching estimate
```{r warning=FALSE, message=FALSE}
library("Matching")
PSM_result <- Match(
  Y = ml_male_df$spend,
  Tr = ml_male_df$treatment,
  X = ml_male_df$ps,
  estimand = "ATT"
)
summary(PSM_result)
```

IPW estimate
```{r warning=FALSE, message=FALSE}
W.out <- weightit(treatment ~ recency + history_segment + channel + zip_code,
  data = ml_male_df,
  ps = ml_male_df$ps,
  method = "ps",
  estimand = "ATE")

# check the balance in the covariates
love.plot(W.out, threshold = 0.1)

# estimate the effect based on the weighted data
IPW_result <- ml_male_df %>%
  lm(data = ., spend ~ treatment, weights = W.out$weights) %>%
  tidy()

IPW_result
```

In this example, email delivery was determined somewhat randomly based on predicted purchases.
However, during the actual analysis, it is possible that there is no randomness in the decision to deliver emails.
For example, if the predicted value is above a certain level, the email will be delivered, but if it is below a certain level, the email will not be delivered.
In this case, the propensity score will always be 1 or 0, and thus cannot be analyzed using methods such as propensity score matching or IPW.
In such a case, it is better to use Regression Discontinuity Design (RDD).