---
title: "HW5 Project2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r warning = FALSE}
library("tidyverse")
library("broom")
library("readxl")
library("ggplot2")
library("psych")
```

```{r warning = FALSE}
# path setup
current_note_path <- getwd()
main_path <- file.path(current_note_path, "582/project/")
df <- read_excel(file.path(main_path, "project2/feeder.xls"))
```

```{r warning = FALSE}
# Assign 'front' or 'back'  based on Distance_from_door since within Distance 1 to 6 and Distance 7 to 12, there are randomly assigned 6 treatments equally.
df2 <- df %>%
    mutate(Position = ifelse(Distance_from_door <= 6, 'front', 'back')) %>%
    # Create a new variable for the group (=Block)
    mutate(Block = interaction(df2$Side, df2$Tier, df2$Position))

View(df2)
write.csv(df2, file = file.path(main_path, "project2/df2.csv"))

```

# 1. Descriptive Statistics
Check the statistical summary of data without considering Time
```{r warning = FALSE}
df2 %>% group_by(Treatment) %>%
  summarize(mean = mean(Production, na.rm = TRUE),
            sd = sd(Production, na.rm = TRUE)) %>%
  # Sort
  arrange(desc(mean)) %>%
  print(n=Inf)
```

Check the statistical summary of data considering Time
```{r warning = FALSE}
df2 %>% group_by(Treatment, Days_in_Trt) %>%
  summarize(mean = mean(Production, na.rm = TRUE)) %>%
  pivot_wider(names_from = Days_in_Trt, values_from = mean)
```

Check the distribution of Production over times in general
```{r warning = FALSE}
# Calculate mean and variance for each day
df_summary <- df2 %>%
  group_by(Days_in_Trt) %>%
  summarise(mean = mean(Production, na.rm = TRUE),
            variance = var(Production, na.rm = TRUE))

# Create a line plot with error bars
ggplot(df_summary, aes(x = Days_in_Trt, y = mean)) +
  geom_line() +
  geom_errorbar(aes(ymin = mean - sqrt(variance), ymax = mean + sqrt(variance)), width = 0.2) +
  theme_minimal() +
  labs(x = "Days Passed after Treatment Installed", y = "Average Production (eggs/hen/day)", title = "Variance of Production Over Time")
```

Check the distribution of Production by treatment
```{r warning = FALSE}
# Calculate mean and variance for each day
df_summary1 <- df2 %>%
  group_by(Treatment, Days_in_Trt) %>%
  summarise(mean = mean(Production, na.rm = TRUE))


# Create a line plot with different lines per Distance_from_door
ggplot(df_summary1, aes(x = Days_in_Trt, y = mean, color = factor(Treatment))) +
  geom_line() +
  theme_minimal() +
  labs(x = "Days in Treatment", y = "Mean Production", color = "Treatment Level", 
       title = "Mean Production Over Time by Treatment Level")
```

Check the distribution of Production over times by Distance
```{r warning = FALSE}
# Calculate mean and variance for each day
df_summary2 <- df2 %>%
  group_by(Distance_from_door, Days_in_Trt) %>%
  summarise(mean = mean(Production, na.rm = TRUE))


# Create a line plot with different lines per Distance_from_door
ggplot(df_summary2, aes(x = Days_in_Trt, y = mean, color = factor(Distance_from_door))) +
  geom_line() +
  theme_minimal() +
  labs(x = "Days in Treatment", y = "Mean Production", color = "Distance from Door", 
       title = "Mean Production Over Time by Distance from Door")


# Run the repeated measures ANOVA
model <- aov(mean ~ Distance_from_door * Days_in_Trt + Error(Distance_from_door/Days_in_Trt), data = df_summary2)

# Print the summary of the model
summary(model)
```

Check the correlation between Consumption and Production
```{r warning = FALSE}
# Check the correlation between Consumption and Production
cor(df2$Consumption, df2$Production, use = "complete.obs")
# Create a scatter plot excluding rows with missing values
ggplot(df2, aes(x = Consumption, y = Production)) +
  geom_point(na.rm = TRUE) +
  theme_minimal()

# Check the correlation matrix
cor(df2 %>% select(Days_in_Trt, Consumption, Production, Treatment), use = "complete.obs")
selected_data <- na.omit(df2 %>% select(Days_in_Trt, Consumption, Production, Treatment))
pairs.panels(selected_data, gap = 0)
```


# Repeated measures ANOVA to compare the average production per Treatment and Time
```{r warning = FALSE}
df2_fill <- df2 %>%
    # Replace NaN values in the Production column with 0
    mutate(Production = replace_na(Production, 0))

# Run the repeated measures ANOVA
library("nlme")
model <- lme(Production ~ Block + Treatment + Days_in_Trt,  random = ~1|Block/Days_in_Trt, data = df2_fill)
model <- aov(Production ~ Block + Treatment + Days_in_Trt + Block:Days_in_Trt, data = df2_fill)

# Print the summary of the model
summary(model)
```

Post-hoc Analysis
After fitting the model, I would use emmeans functions to explore the means. That is material from week 2
and reviewed here.
```{r warning = FALSE}
# Run the post-hoc analysis
library("emmeans")
emmeans(model, pairwise ~ Treatment:Days_in_Trt, adjust = "tukey")
```

# Model Building
When looking at data from a single time point (e.g. the first month), we merely have 12 observations from a randomized complete block design with a single treatment factor.\ 
It can therefore be analyzed with a simple one-way ANOVA (fixed `Production` effect) for randomized complete block designs (fixed `block` effect).\

I treated Block as a fixed effect instead of Side, Tier, and Position and regarded the treatment effect as fixed factors as well. \ 
Since we have repeated measures over time (12 months), I would also include time-related variables as covariates and account for the within-subject correlation structure. \

Also, in a factorial design, the interaction term is likely to be something of interest. However, in a block design, the interaction between block and treatment is an error term, representing random variation of experimental units across treatment. \
```{r warning = FALSE}
library("lme4")
library("nlme")

# # Since the models in this chapter do not contain any random effects, we make use of gls() instead of lmer()
# # It must be clear that “measurements on the same plot are likely to be serially correlated”. Thus, we need to account for the within-subject correlation structure using AR(1).
# gls_v1 <- df2 %>%
#   mutate(Production = replace_na(Production, 0)) %>%
#   gls(model = Production ~ Days_in_Trt * (Block + Treatment), 
#                     correlation = corAR1(form = ~ 1 | Days_in_Trt), # default, i.e. homoscedastic, independent errors
#                     data = .)
# gls_v1_2 <- df2 %>%
#   mutate(Production = replace_na(Production, 0)) %>%
#   gls(model = Production ~ Days_in_Trt * (Block + Treatment), 
#               correlation = corAR1(form = ~ Days_in_Trt | CageID), 
#               data = .)
# gls_v1_2 <- df2 %>%
#   mutate(Production = replace_na(Production, 0)) %>%
#   gls(model = Production ~ Days_in_Trt * (Block + Treatment),  
#               weights = varIdent(form = ~ Days_in_Trt | CageID),
#               data = .)

# gls_v2 <- df2 %>%
#   mutate(Production = replace_na(Production, 0)) %>%
#   gls(Production ~ Treatment * Days_in_Trt + Block, data = .)


# # Extract variance component estimates
# tibble(varstruct = "iid") %>% 
#   mutate(sigma    = gls_v1$sigma) %>% 
#   mutate(Variance = sigma^2)
```


```{r warning = FALSE}
# as a reference, run the simple linear model
base_model <- lm(Production ~ Treatment + Block, data = df2)
# Fits linear mixed-effects model Allowing for random intercepts for each unique value of Date. 
lme_model <- df2 %>%
  mutate(Production = replace_na(Production, 0)) %>%
  lme(Production ~ Days_in_Trt * (Block + Treatment), 
      data = ., 
      random = ~ 1 | CageID, # Random intercepts for CageID
      correlation = corAR1(form = ~ Days_in_Trt | CageID))

lme_model_v2 <- df2 %>%
  mutate(Production = replace_na(Production, 0)) %>%
  lme(Production ~ Days_in_Trt * (Block + Treatment), 
      data = ., 
      random = ~ 1 | CageID,  # Random intercepts for CageID
      weights = varIdent(form = ~ 1 | Treatment))

summary(base_model)
summary(lme_model)
summary(lme_model_v2)


# Check the normality of the residuals -> violations of the normality
df2$lme_residuals <- residuals(lme_model)
plot(fitted(lme_model), residuals(lme_model))
qqnorm(resid(lme_model))
qqline(resid(lme_model), col = "red")
```

Log transformation of the response variable
```{r warning = FALSE}
# Try to transform the response data
df2$Production_log <- ifelse(is.na(df2$Production), log(1), log(df2$Production + 1)) # Adding 1 to avoid log(0)
View(df2)

# Fit the model with the transformed response variable
lme_model_logtransformed <- df2 %>%
  lme(Production_log ~ Days_in_Trt * (Block + Treatment), 
      data = ., 
      random = ~ 1 | CageID, # Random intercepts for CageID
      correlation = corAR1(form = ~ Days_in_Trt | CageID))

# Check the normality of the residuals -> violations of the normality
plot(fitted(lme_model_logtransformed), residuals(lme_model_logtransformed))
qqnorm(resid(lme_model_logtransformed))
qqline(resid(lme_model_logtransformed), col = "red")

summary(lme_model_logtransformed)
```

Box-Cox transformation of the response variable
```{r warning = FALSE}
library("MASS")
# Replace NA values with 0
df2_modified <- df2 %>% mutate(Production = ifelse(is.na(Production) | Production <= 0, 0.01, Production + 0.01))
View(df2_modified)

# Perform Box-Cox transformation
bc <- boxcox(lm(Production ~ Days_in_Trt * (Block + Treatment), data = df2_modified))
lambda <- bc$x[which.max(bc$y)]
df2$Production_bc <- (df2$Production^lambda - 1) / lambda

# Refit the model with the Box-Cox transformed response variable
lme_model_bc <- df2 %>%
  drop_na(Production) %>%
  lme(Production_bc ~ Days_in_Trt * (Block + Treatment), 
      data = ., 
      random = ~ 1 | CageID)
# Check the normality of the residuals -> violations of the normality
plot(fitted(lme_model_bc), residuals(lme_model_bc))
qqnorm(resid(lme_model_bc))
qqline(resid(lme_model_bc), col = "red")

summary(lme_model_bc)
```
```{r warning = FALSE}
summary(gls_v1_2)
summary(gls_v2)
```

```{r warning = FALSE}
# Extract the estimated coefficients from the gls model using the coef() function:
coefficients <- coef(gls_v1)
predict(gls_v1)
```

```{r warning = FALSE}
# Define the levels of our factors
Treatment_levels <- unique(df2$Treatment)
Block_levels <- unique(df2$Block)
Days_in_Trt_levels <- unique(df2$Days_in_Trt)



# Generate a new dataset
new_data <- expand.grid(Treatment = Treatment_levels, 
                        Block = Block_levels, 
                        Days_in_Trt = Days_in_Trt_levels)
write.csv(new_data, file = file.path(main_path, "project2/new_data.csv"))
View(new_data)
# Predicting without adding random Production values
new_data$Predicted_Production_bc <- predict(lme_model_bc, newdata = new_data, level = 0)

# Transform the predictions back to the original scale
new_data$Predicted_Production <- (lambda * new_data$Predicted_Production_bc + 1)^(1/lambda)

# Identifying the best treatment
best_treatment <- new_data %>%
  arrange(desc(Predicted_Production)) %>%
  top_n(1, Predicted_Production)

# Identifying the best treatment based on the mean predicted Production
new_data %>%
  arrange(desc(Predicted_Production)) %>%
  group_by(Treatment)  %>%
  summarise(mean_Predicted_Production = mean(Predicted_Production, na.rm = TRUE)) %>%
  top_n(1, mean_Predicted_Production)


# # Add a Production column with random values
# # Adjust the parameters of the runif function as needed
# new_data$Production <- runif(nrow(new_data))

# # Apply the gls_v1 model to the new dataset
# new_data$Predicted_Production <- predict(gls_v1, newdata = new_data)

# # Find the combination of factors that gives the maximum predicted Production value
# best_treatment <- new_data %>%
#   filter(Predicted_Production == max(Predicted_Production))

# best_treatment
```