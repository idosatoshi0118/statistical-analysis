---
title: "STAT 656 HW 2"
author: "Satoshi Ido (ID: 34788706)"
date: 1 October 2023
output: pdf_document
---
```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE)
```

```{r}
library("ggplot2")
library("dplyr")
library("tidyr")
library("MASS")
library("fs")
library("moments")
library("rstan")
library("bayesplot")
library("StanHeaders")
```

set options to speed up the calculations
```{r}
# to avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
# for execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores())
# set the size of the plots
options(repr.plot.width = 12, repr.plot.height = 6)

# options(bayesplot::theme_default())
bayesplot_theme_set(theme_default(base_size = 24, base_family = "sans"))
```

```{r}
# Create the input_dir (input directory)
current_note_path <- getwd()
INPUT_DIR <- file.path(current_note_path, "656/hw/hw2/data")

# If INPUT_DIR has not been created yet, create it
if (!dir.exists(INPUT_DIR)) {
  dir.create(INPUT_DIR)
}

# Create the output_dir (output directory)
OUTPUT_DIR <- file.path(current_note_path, "656/hw/hw2/outputs")

# If OUTPUT_DIR has not been created yet, create it
if (!dir.exists(OUTPUT_DIR)) {
  dir.create(OUTPUT_DIR)
}

# Read CSV files using a function to specify the directory automatically
read_csv <- function(name, ...) {
  path <- file.path(INPUT_DIR, paste0(name, ".csv"))
  print(paste("Load:", path))
  return(read.csv(path, ...))
}
```

# Synthetic data
The file `hw2 synthetic.csv` is a dataset of count-valued measurements \(y = \{y_1 , \ldots , y_n\}\), with \(y_i \in \{0, 1, \ldots\}\). Each output \(y_i\) has an associated \(x_i = (x_{i,1}, x_{i,2}) \in \mathbb{R}^2\), and write \(x = \{x_1, \ldots, x_n\}^{\prime}\) as \(x\). We model \(y_i\) as
\[y_i | \beta \sim \text{Poisson}(e^{f(x_i,\beta)})\]
Here, the exponential is to ensure the Poisson rate is always positive, and the function \(f(x_i,\beta) = \beta_0 + \beta_1x_{i,1} + \beta_2x_{i,2} + \beta_3x_{i,1}^2 + \beta_4x_{i,2}^2 + \beta_5x_{i,1}x_{i,2}\).

1. With the provided data, perform a Bayesian analysis on the parameters of the model above to decide which terms in the expression for f(x) you think are important. \
State clearly what your prior over Î² is, and how you arrived at your conclusion, including any useful figures (especially of the posterior distribution). You can use Stan.
```{r}
df <- read.csv("/Users/satoshiido/Documents/statistical-analysis/656/hw/hw2/data/hw2_synthetic.csv")
head(df)
```

Summary of data
```{r}
summary(df)
paste0("sd of x1:", sd(df$x1), " sd of x2: ", sd(df$x2))
```

Histogram of data
```{r}
hist(df$x1)
hist(df$x2)
```

## Regular Poisson model
```{r}
glm1 <- glm(formula = y ~ x1 + x2 + I(x1^2) + I(x2^2) + x1:x2,
            family  = poisson(link = "log"),
            offset  = rep(1, nrow(df)),
            data    = df)
summary(glm1)
```

## Data Creation
Model Specification in Stan
```{r}

poissonreg_normal_code = "
// Poisson model with normal prior

// Data are things you observe/condition on
data {
  // number of data items
  int<lower=1> N;
  // Number of beta parameters (predictors)
  int<lower=1> p;
  // std dev of the prior
  real<lower=0> pr_sd;

  // offset
  // real offset[N];

  // count outcome (output vector)
  int<lower=0> y[N];

}

parameters {
  // Parameters to estimate
  vector[p] beta;
}

// useful to avoid repeating calculations
// note that stan will return values of these variables for each MCMC sample
transformed parameters {
  vectior[N] 
  
  for (i in 1:N) {
    // Linear predictor
    lp[i] = beta[1] + beta[2] * x1[i] + beta[3] * x2[i] + beta[4] * x1_sq[i] + beta[5] * x2_sq[i] + beta[6] * x1_x2[i];

    // Mean (= lambda) for Poisson 
    mu[i] = exp(lp[i]);
  }
}

transformed parameters {
  vector[N] mu = x * beta;
}

// The actual Bayesian model goes here
// I set normal dist as a prior for beta
model {
  // priors
  beta ~ normal(0, pr_sd);  // Note: beta is k-dim
  
  // likelihood
  y ~ poisson(mu);  // likelihood
}
"

# build the model before sampling
poissonreg_normal <- stan_model(model_code = poissonreg_normal_code)

```

data preparation
```{r}
modMat <- as.data.frame(model.matrix(glm1))
# modMat$offset <- 1
names(modMat) <- c("intercept", "x1", "x2", "x1_sq", "x2_sq", "x1_x2")
dat <- as.list(modMat)
dat$y <- df$y
dat$N <- nrow(modMat)
dat$p <- ncol(modMat)
# set the prior sd slightly large than the sd of the data to make it less informative
dat$pr_sd <- 10
```

compile the model

Regression model: \(y = \{y_1 , \ldots , y_n\}\), with \(y_i \in \{0, 1, \ldots\}\). Each output \(y_i\) has an associated \(x_i = (x_{i,1}, x_{i,2}) \in \mathbb{R}^2\), and write \(x = \{x_1, \ldots, x_n\}^{\prime}\) as \(x\). We model \(y_i\) as
\[y_i | \beta \sim \text{Poisson}(e^{f(x_i,\beta)})\]
```{r}
# reg1_data <- list(N = nrow(X), K = 6, pr_sd = 100, x = X, y = y)
# run the built model with given data (chains = 2 can  be okay for verification process, but it should be 4 or more for the actual analysis)
nfit <- stan(
  model_code = poissonreg_normal,
  data = dat,
  iter = 8000,
  warmup = 2000,
  chains = 2
)
```

```{r}
# save the model
saveRDS(nfit, file = file.path(OUTPUT_DIR, "nfit.rds"))
# read the model (-> In this way, no need to run the model again)
# nfit <- readRDS(file = file.path(OUTPUT_DIR, "nfit.rds"))
```

```{r}
post_smp <- as.data.frame(nfit)
colnames(post_smp)[0:2] <- colnames(X)
mcmc_areas(post_smp[,0:2], pars = colnames(X)[0:2], prob = 0.8)
```

```{r}
# trace plot
stan_trace(nfit, pars = c("beta", "sigma"))
```

```{r}
# posterior histogram plot
stan_hist(nfit, pars = c("beta", "sigma"))
```

```{r}
# density plot
stan_dens(nfit, pars = c("beta", "sigma"), separate_chains = TRUE)
```

```{r}
# auto correlation plot
stan_ac(nfit, pars = c("beta", "sigma"), separate_chains = TRUE)
```



# Applied problem

## first design selection
My first approach is to run the eperiments with 24 wells initially, followed by 48 wells in the second experiments. 
The reason for this is that I want to see if the 24 wells are enough to get the information about the mean and variance of the population so that I can set a reasonable prior for the second experiment.
I will assign pairs of concentrations for the two chemical modulators to each well in the manner as below. The main focus is to see how the effect of the one modulator changes depending on the concentration of the other modulator.
Since I have little idea of the effect of the modulators, I will assign the concentrations of the modulators somewhat randomly.
```{r}
design1 <- matrix(nrow = 24, ncol = 2)
# assign the concentration of the modulators randomly
## set a seed to reproduce the same result
set.seed(49)
modA <- rep(seq(0, 75, by = 15), each = 4)
modB <- rep(seq(0, 30, by = 10), times = 6)
design1 <- cbind(modA, modB)
output_path <- file.path(OUTPUT_DIR, "design1.csv")
# write a table and save it to csv
# write.table(design1, file = output_path, sep = ",", col.names = F, row.names = F)
```


