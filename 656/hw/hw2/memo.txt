```{r}
poissonreg_pirornormal_code = "
// Data are things you observe/condition on
data {
  // number of data items (an integer)
  int<lower=0> N;
  // Number of beta parameters (predictors)
  int<lower=0> p;
  int<lower=0> K;      // number of predictors
  real<lower=0> pr_sd; // std dev of the prior
  matrix[N, p-1] x;      // predictor matrix

  // Covariates
  int <lower=0, upper=1> intercept[N];
  int <lower=0, upper=1> x1[N];
  int <lower=0, upper=1> x2[N];
  int <lower=0, upper=1> x1^2[N];
  int <lower=0, upper=1> x2^2[N];
  int <lower=0, upper=1> x1*x2[N];

  // offset
  real offset[N];

  // count outcome (output vector)
  int<lower=0> y[N];

}
// Parameters to estimate
parameters {
  // vector[K] beta;       // coefficients for predictors
  // real<lower=0> sigma;  // error scale
  real<lower=0> lambda[N]; // Poisson rate
  real beta[p];
}
// useful to avoid repeating calculations
// note that stan will return values of these variables
// for each MCMC sample
transformed parameters {
  
  real lp[N];
  real <lower=0> mu[N];
  vector[N] lambda = exp(x * beta); // Poisson rate
  
  for (i in 1:N) {
    // Linear predictor
    // lp[i] = poisson_log_lpmf(y[i] | lambda[i]);
    lp[i] <- beta[1] + beta[2] * x1[i] + beta[3] * x2[i] + beta[4] * x1[i]^2 + beta[5] * x2[i]^2 + beta[6] * x1[i] * x2[i] + offset[i];
    mu[i] = exp(lp[i]);

    // Mean (= lambda) for Poisson 
    mu[i] <- exp(lp[i]);
  }
}
// The actual Bayesian model goes here
// This is the prior and likelihood and I set normal dist as a prior for beta
model {
  // priors
  beta ~ normal(0,pr_sd);  // Note: beta is k-dim
  // sigma ~ inv_gamma(0.001,0.001);  // Close to a flat prior
  
  // likelihood
  y ~ poisson(mu);  // likelihood
}
// useful for posterior predictive checks
// Stan's posterior sampler will account for the estimation uncertainty
// generated quantities {
  // define variables that are computed or generated during the execution of the model's sampling algorithm
  // int<lower=0> y_tilde[N];
  // for (i in 1:N) {
  //  y_tilde[i] = poisson_rng(lambda[i]);
  // }
  // vector[N] f = beta[1] + beta[2] * x[,1] + beta[3] * x[,2] + beta[4] * x[,1].^2 + beta[5] * x[,2].^2 + beta[6] * x[,1] .* x[,2];
  
// } 
"

library(conflicted)
conflict_prefer("sampling", "rstan")
```







poissonreg_normal_code = "
// Poisson model with normal prior

// Data are things you observe/condition on
data {
  // number of data items
  int<lower=0> N;
  // Number of beta parameters (predictors)
  int<lower=0> p;
  // std dev of the prior
  real<lower=0> pr_sd;

  // Covariates
  real intercept[N];
  real x1[N];
  real x2[N];
  real x1_sq[N];
  real x2_sq[N];
  real x1_x2[N];

  // offset
  // real offset[N];

  // count outcome (output vector)
  int<lower=0> y[N];

}

parameters {
  // Parameters to estimate
  real beta[p];
  // vector[p] beta;
}

// useful to avoid repeating calculations
// note that stan will return values of these variables for each MCMC sample
transformed parameters {
  real lp[N];
  real <lower=0> mu[N];
  
  for (i in 1:N) {
    // Linear predictor
    lp[i] = beta[1] + beta[2] * x1[i] + beta[3] * x2[i] + beta[4] * x1_sq[i] + beta[5] * x2_sq[i] + beta[6] * x1_x2[i];

    // Mean (= lambda) for Poisson 
    mu[i] = exp(lp[i]);
  }
}

transformed parameters {
  vector[N] mu = x * beta;
}

// The actual Bayesian model goes here
// I set normal dist as a prior for beta
model {
  // priors
  beta ~ normal(0, pr_sd);  // Note: beta is k-dim
  
  // likelihood
  y ~ poisson(mu);  // likelihood
}
"

# build the model before sampling
poissonreg_normal <- stan_model(model_code = poissonreg_normal_code)






```{r}
plot(post_smp$, type = 'l')
```

```{r}
# trace plot
stan_trace(nfit, pars = colnames(X))
```

```{r}
# posterior histogram plot
stan_hist(nfit, pars = c("beta", "sigma"))
```

```{r}
# density plot
stan_dens(nfit, pars = c("beta", "sigma"), separate_chains = TRUE)
```

```{r}
# auto correlation plot
stan_ac(nfit, pars = c("beta", "sigma"), separate_chains = TRUE)
```





# Applied problem

## Second design
### Try to make the polynomial regression without A_sq

Try without `A_sq`
```{r}
# create the data for stan simulation
X <- design1_result[, c("A", "B", "B_sq", "A_B")]
X[, "Offset"] <- 1
y <- design1_result$y

# compile the model
reg2_data <- list(N = nrow(X), p = ncol(X), x = X, y = y, pr_sd = 100)
reg_fit_without_A_sq <- rstan::sampling(
  object = reg_half_cauchy,
  data = reg2_data,
  iter = 10000,
  warmup = 2000,
  chains = 2
)
# save the model
saveRDS(reg_fit_without_A_sq, file = "/Users/satoshiido/Documents/statistical-analysis/656/hw/hw2/outputs/reg_fit_without_A_sq.rds")
# read the model
reg_fit_without_A_sq <- readRDS(file = "/Users/satoshiido/Documents/statistical-analysis/656/hw/hw2/outputs/reg_fit_without_A_sq.rds")
# turn the posterior samples into a data frame
post_smp_reg <- as.data.frame(reg_fit_without_A_sq)
# rename the columns
colnames(post_smp_reg)[1:5] <- colnames(X)
mcmc_areas(post_smp_reg[, 1:5], pars = colnames(X)[1:5], prob = 0.8)

# compile the model
predictive_means_without_A_sq <- apply(grid, 1, function(row) {
  modulator_A <- row["modulator_A"]
  modulator_B <- row["modulator_B"]

  # Compute the predictive mean using the model equation and the posterior samples
  mean_predictive <- mean(post_smp_reg$A * modulator_A +
                          post_smp_reg$B * modulator_B +
                          post_smp_reg$B_sq * modulator_B^2 +
                          post_smp_reg$A_B * (modulator_A * modulator_B))
  return(mean_predictive)
})

# Add the computed predictive means to the grid
grid$predictive_mean <- predictive_means_without_A_sq

# Plot the contour
ggplot(grid, aes(x = modulator_A, y = modulator_B, z = predictive_mean)) +
  geom_contour(aes(color = ..level..)) +
  scale_color_viridis_c() +
  labs(title = "Contour Plot of Posterior Predictive Mean of Conversion",
       x = "Modulator A",
       y = "Modulator B",
       color = "Predictive Mean") +
  theme_minimal()

```